{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aluno: Giovanni Bruno Travassos de Carvalho - 11506849\n",
    "\n",
    "Resolução da primeira questão da primeira lista de exercícios de Deep Learning\n",
    "\n",
    "Professor: Tiago Maritan "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Questão 1 \n",
    "A representação de uma determinada mensagem digital ternária, isto é formada por três bits,\n",
    "forma um cubo cujos vértices correspondem a mesma representação digital. Supondo que ao\n",
    "transmitirmos esta mensagem a mesma possa ser contaminada por ruído formado em torno de\n",
    "cada vértice uma nuvem esférica de valores aleatórios com raio máximo é 0.1. Formule este\n",
    "problema como um problema de classificação de padrões e treine uma rede Perceptron de\n",
    "Rosenblatt (Perceptron de camada única) para atuar como classificador/decodificador. Para\n",
    "solução do problema defina antes um conjunto de treinamento e um conjunto de validação.\n",
    "\n",
    "Dica: O problema pode ser formulado como um problema de classificação de 8 padrões diferentes, sendo que cada padrão representa um vértice do cubo. \n",
    "\n",
    "Padrão 1: x = {0,0,0} com vetor resposta d = {1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0}\n",
    "\n",
    "Padrão 2: x = {0,0,1} com vetor resposta d = {-1.0, 1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0}\n",
    "\n",
    "Padrão 3: x = {0,1,0} com vetor resposta d = {-1.0, -1.0, 1.0, -1.0, -1.0, -1.0, -1.0, -1.0}\n",
    "\n",
    "Padrão 4: x = {0,1,1} com vetor resposta d = {-1.0, -1.0, -1.0, 1.0, -1.0, -1.0, -1.0, -1.0}\n",
    "\n",
    "Padrão 5: x = {1,0,0} com vetor resposta d = {-1.0, -1.0, -1.0, -1.0, 1.0, -1.0, -1.0, -1.0}\n",
    "\n",
    "Padrão 6: x = {1,0,1} com vetor resposta d = {-1.0, -1.0, -1.0, -1.0, -1.0, 1.0, -1.0, -1.0}\n",
    "\n",
    "Padrão 7: x = {1,1,0} com vetor resposta d = {-1.0, -1.0, -1.0, -1.0, -1.0, -1.0, 1.0, -1.0}\n",
    "\n",
    "Padrão 8: x = {1,1,1} com vetor resposta d = {-1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0, 1.0}\n",
    "\n",
    "Dica: -1 pode ser trocado para 0, mudando a função de ativação "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Primeira Etapa: Criação do Arquivo de Entrada \n",
    "\n",
    "Objetivo: Criar um conjunto de dados seguindo os padrões, porém com variação randômica de ruído em algumas instâncias. \n",
    "    Serão criados 800 entradas. \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import random \n",
    "\n",
    "random.seed(234) \n",
    "    # Criada uma semente para garantir que sempre seja obtido o mesmo conjunto de dados \n",
    "    \n",
    "padroes = [[0, 0, 0], [0, 0, 1], [0, 1, 0], [0, 1, 1], \n",
    "           [1, 0, 0], [1, 0, 1], [1, 1, 0], [1, 1, 1]] # 8 tipos de padrões normais\n",
    "\n",
    "ruidoMax = 0.1 \n",
    "    # Ruído máximo de 0.1 \n",
    "\n",
    "amostras = 100 \n",
    "    # Número de amostras para cada tipo de entrada \n",
    "    \n",
    "count=0\n",
    "coluna = len(padroes[0])\n",
    "linha = len(padroes)*amostras\n",
    "ruido = [0]*coluna \n",
    "\n",
    "arquivo = open('./entradas.txt', 'w')\n",
    "lista = []\n",
    "\n",
    "for i in range (0, len(padroes)): \n",
    "    \n",
    "    for j in range(0,amostras): \n",
    "        \n",
    "        for k in range(0,coluna):\n",
    "            ruido[k] = random.randrange(0,2) \n",
    "                # 0 = sem ruído\n",
    "                # 1 = com ruído\n",
    "        for k in range(0,coluna): \n",
    "            if(ruido[k]==0):\n",
    "                a = padroes[i][k]\n",
    "                arquivo.write(str(a))\n",
    "                lista.append(a)\n",
    "            else:\n",
    "                a = padroes[i][k] + random.uniform(-ruidoMax, ruidoMax)\n",
    "                arquivo.write(str(a)) # Acrescenta o ruído \n",
    "                lista.append(a)\n",
    "            if(k==2):\n",
    "                arquivo.write('\\n')\n",
    "            else: \n",
    "                arquivo.write(',')\n",
    "        count+=1 \n",
    "\n",
    "arquivo.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Segunda Etapa: Criação do Arquivo de Saída\n",
    "\n",
    "Objetivo: Para cada linha do arquivo de entrada, encontrar o seu binário de 8bits equivalente. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "tamSaida = len(lista)\n",
    "i = 0; aux = 0\n",
    "codeBin = [0]*coluna \n",
    "peso = [2,1,0]\n",
    "saida = [0]*8 \n",
    "\n",
    "arquivo2 = open('./saida.txt','w')\n",
    "\n",
    "while(i < tamSaida):\n",
    "    \n",
    "    for j in range (0,coluna): \n",
    "        if(lista[i] <= 0.1): \n",
    "            # Valores que forem menores que 0.1 são equivalentes a 0 \n",
    "            codeBin[j]=0\n",
    "        else: \n",
    "            # Valores maiores que 0.9 são equivalentes a 1 \n",
    "            codeBin[j]=1\n",
    "        i+=1\n",
    "    \n",
    "    for g in range(coluna-1, -1, -1):\n",
    "        aux += codeBin[g] * (2 **peso[g])\n",
    "        # Calcula o número decimal equivalente ao binário da saída \n",
    "    \n",
    "    saida[aux] = 1 # Seta o bit para 1 \n",
    "    \n",
    "    for k in range (0,8):\n",
    "        arquivo2.write(str(saida[k]))\n",
    "        \n",
    "        if(k!=7):\n",
    "            arquivo2.write(',')\n",
    "        else: \n",
    "            arquivo2.write(\"\\n\")\n",
    "            \n",
    "    aux = 0\n",
    "    saida=[0]*8 # Seta para -1 o vetor de saída para ser reescrito \n",
    "\n",
    "arquivo2.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nas primeiras etapas foram criados dois arquivos com 800 instâncias cada, sendo 100 para cada tipo de padrão. \n",
    "\n",
    "### Terceira Etapa: Rede Neural - Perceptron de Rosenblatt "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "    # Importação das bibliotecas "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = []\n",
    "X = np.loadtxt('../entradas.txt', dtype=float, delimiter=',', encoding = 'bytes')\n",
    "\n",
    "Y = []\n",
    "Y = np.loadtxt('../saida.txt', dtype=float, delimiter=',', encoding = 'bytes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.0715832   0.08466661  0.        ]\n",
      " [-0.0306616   0.         -0.00156604]\n",
      " [ 0.         -0.02204448  0.03691852]\n",
      " ...\n",
      " [ 1.          0.95714442  1.        ]\n",
      " [ 1.0076904   0.96645834  1.        ]\n",
      " [ 1.08147671  0.95129295  0.992824  ]]\n"
     ]
    }
   ],
   "source": [
    "print(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1. 0. 0. ... 0. 0. 0.]\n",
      " [1. 0. 0. ... 0. 0. 0.]\n",
      " [1. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 1.]\n",
      " [0. 0. 0. ... 0. 0. 1.]\n",
      " [0. 0. 0. ... 0. 0. 1.]]\n"
     ]
    }
   ],
   "source": [
    "print(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dividindo o conjunto em dados de Treino e de Teste: \n",
    "\n",
    "X_Treino, X_Teste, Y_Treino, Y_Teste = train_test_split(X, Y, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalização com Standard Scaler \n",
    "# Standard Scaler implementa a TransformerAPI para calcular a média e o desvio padrão em um conjunto de treinamento\n",
    "\n",
    "ss = StandardScaler()\n",
    "X_Treino = ss.fit_transform(X_Treino)\n",
    "X_Teste = ss.fit_transform(X_Teste)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_Teste)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criando a Rede Neural: \n",
    "\n",
    "redeNeural = tf.keras.models.Sequential()\n",
    "    # Como é um Perceptron Simples, só tem a camada de entrada e a saída \n",
    "redeNeural.add(tf.keras.layers.Dense(units=3, activation='relu')) # Camada de Entrada\n",
    "redeNeural.add(tf.keras.layers.Dense(units=8, activation='sigmoid')) # Camada de Saída "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Giovanni\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "# Compilando a Rede Neural: \n",
    "\n",
    "redeNeural.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 512 samples, validate on 128 samples\n",
      "Epoch 1/100\n",
      "512/512 [==============================] - 0s 219us/sample - loss: 0.0927 - acc: 0.9780 - val_loss: 0.0978 - val_acc: 0.9717\n",
      "Epoch 2/100\n",
      "512/512 [==============================] - 0s 383us/sample - loss: 0.0914 - acc: 0.9778 - val_loss: 0.0966 - val_acc: 0.9717\n",
      "Epoch 3/100\n",
      "512/512 [==============================] - 0s 287us/sample - loss: 0.0902 - acc: 0.9783 - val_loss: 0.0953 - val_acc: 0.9727\n",
      "Epoch 4/100\n",
      "512/512 [==============================] - 0s 285us/sample - loss: 0.0890 - acc: 0.9783 - val_loss: 0.0940 - val_acc: 0.9727\n",
      "Epoch 5/100\n",
      "512/512 [==============================] - 0s 320us/sample - loss: 0.0878 - acc: 0.9790 - val_loss: 0.0929 - val_acc: 0.9727\n",
      "Epoch 6/100\n",
      "512/512 [==============================] - 0s 264us/sample - loss: 0.0866 - acc: 0.9790 - val_loss: 0.0917 - val_acc: 0.9736\n",
      "Epoch 7/100\n",
      "512/512 [==============================] - 0s 219us/sample - loss: 0.0855 - acc: 0.9790 - val_loss: 0.0905 - val_acc: 0.9736\n",
      "Epoch 8/100\n",
      "512/512 [==============================] - 0s 213us/sample - loss: 0.0844 - acc: 0.9797 - val_loss: 0.0894 - val_acc: 0.9756\n",
      "Epoch 9/100\n",
      "512/512 [==============================] - 0s 203us/sample - loss: 0.0832 - acc: 0.9797 - val_loss: 0.0883 - val_acc: 0.9766\n",
      "Epoch 10/100\n",
      "512/512 [==============================] - 0s 221us/sample - loss: 0.0821 - acc: 0.9795 - val_loss: 0.0870 - val_acc: 0.9766\n",
      "Epoch 11/100\n",
      "512/512 [==============================] - 0s 238us/sample - loss: 0.0810 - acc: 0.9797 - val_loss: 0.0859 - val_acc: 0.9766\n",
      "Epoch 12/100\n",
      "512/512 [==============================] - 0s 248us/sample - loss: 0.0799 - acc: 0.9807 - val_loss: 0.0848 - val_acc: 0.9766\n",
      "Epoch 13/100\n",
      "512/512 [==============================] - 0s 221us/sample - loss: 0.0789 - acc: 0.9810 - val_loss: 0.0837 - val_acc: 0.9775\n",
      "Epoch 14/100\n",
      "512/512 [==============================] - 0s 193us/sample - loss: 0.0778 - acc: 0.9824 - val_loss: 0.0827 - val_acc: 0.9775\n",
      "Epoch 15/100\n",
      "512/512 [==============================] - 0s 217us/sample - loss: 0.0768 - acc: 0.9827 - val_loss: 0.0816 - val_acc: 0.9785\n",
      "Epoch 16/100\n",
      "512/512 [==============================] - 0s 172us/sample - loss: 0.0757 - acc: 0.9827 - val_loss: 0.0806 - val_acc: 0.9795\n",
      "Epoch 17/100\n",
      "512/512 [==============================] - 0s 180us/sample - loss: 0.0747 - acc: 0.9834 - val_loss: 0.0796 - val_acc: 0.9795\n",
      "Epoch 18/100\n",
      "512/512 [==============================] - 0s 199us/sample - loss: 0.0737 - acc: 0.9836 - val_loss: 0.0786 - val_acc: 0.9795\n",
      "Epoch 19/100\n",
      "512/512 [==============================] - 0s 178us/sample - loss: 0.0728 - acc: 0.9839 - val_loss: 0.0776 - val_acc: 0.9795\n",
      "Epoch 20/100\n",
      "512/512 [==============================] - 0s 236us/sample - loss: 0.0718 - acc: 0.9839 - val_loss: 0.0766 - val_acc: 0.9795\n",
      "Epoch 21/100\n",
      "512/512 [==============================] - 0s 203us/sample - loss: 0.0709 - acc: 0.9849 - val_loss: 0.0757 - val_acc: 0.9795\n",
      "Epoch 22/100\n",
      "512/512 [==============================] - 0s 201us/sample - loss: 0.0699 - acc: 0.9851 - val_loss: 0.0748 - val_acc: 0.9795\n",
      "Epoch 23/100\n",
      "512/512 [==============================] - 0s 183us/sample - loss: 0.0690 - acc: 0.9856 - val_loss: 0.0738 - val_acc: 0.9795\n",
      "Epoch 24/100\n",
      "512/512 [==============================] - 0s 189us/sample - loss: 0.0681 - acc: 0.9858 - val_loss: 0.0729 - val_acc: 0.9795\n",
      "Epoch 25/100\n",
      "512/512 [==============================] - 0s 197us/sample - loss: 0.0672 - acc: 0.9861 - val_loss: 0.0720 - val_acc: 0.9805\n",
      "Epoch 26/100\n",
      "512/512 [==============================] - 0s 183us/sample - loss: 0.0663 - acc: 0.9866 - val_loss: 0.0710 - val_acc: 0.9814\n",
      "Epoch 27/100\n",
      "512/512 [==============================] - 0s 189us/sample - loss: 0.0655 - acc: 0.9868 - val_loss: 0.0701 - val_acc: 0.9814\n",
      "Epoch 28/100\n",
      "512/512 [==============================] - 0s 182us/sample - loss: 0.0646 - acc: 0.9871 - val_loss: 0.0693 - val_acc: 0.9824\n",
      "Epoch 29/100\n",
      "512/512 [==============================] - 0s 211us/sample - loss: 0.0638 - acc: 0.9873 - val_loss: 0.0683 - val_acc: 0.9844\n",
      "Epoch 30/100\n",
      "512/512 [==============================] - 0s 185us/sample - loss: 0.0630 - acc: 0.9875 - val_loss: 0.0675 - val_acc: 0.9844\n",
      "Epoch 31/100\n",
      "512/512 [==============================] - 0s 187us/sample - loss: 0.0621 - acc: 0.9878 - val_loss: 0.0666 - val_acc: 0.9844\n",
      "Epoch 32/100\n",
      "512/512 [==============================] - 0s 217us/sample - loss: 0.0614 - acc: 0.9878 - val_loss: 0.0658 - val_acc: 0.9844\n",
      "Epoch 33/100\n",
      "512/512 [==============================] - 0s 182us/sample - loss: 0.0606 - acc: 0.9880 - val_loss: 0.0651 - val_acc: 0.9844\n",
      "Epoch 34/100\n",
      "512/512 [==============================] - 0s 180us/sample - loss: 0.0599 - acc: 0.9885 - val_loss: 0.0642 - val_acc: 0.9854\n",
      "Epoch 35/100\n",
      "512/512 [==============================] - 0s 189us/sample - loss: 0.0590 - acc: 0.9910 - val_loss: 0.0635 - val_acc: 0.9873\n",
      "Epoch 36/100\n",
      "512/512 [==============================] - 0s 209us/sample - loss: 0.0583 - acc: 0.9932 - val_loss: 0.0627 - val_acc: 0.9873\n",
      "Epoch 37/100\n",
      "512/512 [==============================] - 0s 176us/sample - loss: 0.0576 - acc: 0.9941 - val_loss: 0.0619 - val_acc: 0.9893\n",
      "Epoch 38/100\n",
      "512/512 [==============================] - 0s 197us/sample - loss: 0.0568 - acc: 0.9944 - val_loss: 0.0612 - val_acc: 0.9893\n",
      "Epoch 39/100\n",
      "512/512 [==============================] - 0s 197us/sample - loss: 0.0561 - acc: 0.9944 - val_loss: 0.0605 - val_acc: 0.9893\n",
      "Epoch 40/100\n",
      "512/512 [==============================] - 0s 185us/sample - loss: 0.0555 - acc: 0.9946 - val_loss: 0.0597 - val_acc: 0.9912\n",
      "Epoch 41/100\n",
      "512/512 [==============================] - 0s 191us/sample - loss: 0.0548 - acc: 0.9949 - val_loss: 0.0590 - val_acc: 0.9912\n",
      "Epoch 42/100\n",
      "512/512 [==============================] - 0s 185us/sample - loss: 0.0540 - acc: 0.9954 - val_loss: 0.0583 - val_acc: 0.9912\n",
      "Epoch 43/100\n",
      "512/512 [==============================] - 0s 182us/sample - loss: 0.0534 - acc: 0.9958 - val_loss: 0.0577 - val_acc: 0.9912\n",
      "Epoch 44/100\n",
      "512/512 [==============================] - 0s 195us/sample - loss: 0.0527 - acc: 0.9961 - val_loss: 0.0570 - val_acc: 0.9912\n",
      "Epoch 45/100\n",
      "512/512 [==============================] - 0s 195us/sample - loss: 0.0520 - acc: 0.9958 - val_loss: 0.0563 - val_acc: 0.9922\n",
      "Epoch 46/100\n",
      "512/512 [==============================] - 0s 209us/sample - loss: 0.0514 - acc: 0.9961 - val_loss: 0.0557 - val_acc: 0.9922\n",
      "Epoch 47/100\n",
      "512/512 [==============================] - 0s 226us/sample - loss: 0.0508 - acc: 0.9961 - val_loss: 0.0550 - val_acc: 0.9932\n",
      "Epoch 48/100\n",
      "512/512 [==============================] - 0s 193us/sample - loss: 0.0502 - acc: 0.9971 - val_loss: 0.0544 - val_acc: 0.9932\n",
      "Epoch 49/100\n",
      "512/512 [==============================] - 0s 223us/sample - loss: 0.0496 - acc: 0.9971 - val_loss: 0.0538 - val_acc: 0.9951\n",
      "Epoch 50/100\n",
      "512/512 [==============================] - 0s 209us/sample - loss: 0.0490 - acc: 0.9971 - val_loss: 0.0532 - val_acc: 0.9951\n",
      "Epoch 51/100\n",
      "512/512 [==============================] - 0s 203us/sample - loss: 0.0484 - acc: 0.9976 - val_loss: 0.0526 - val_acc: 0.9961\n",
      "Epoch 52/100\n",
      "512/512 [==============================] - 0s 234us/sample - loss: 0.0478 - acc: 0.9978 - val_loss: 0.0520 - val_acc: 0.9961\n",
      "Epoch 53/100\n",
      "512/512 [==============================] - 0s 209us/sample - loss: 0.0472 - acc: 0.9978 - val_loss: 0.0514 - val_acc: 0.9961\n",
      "Epoch 54/100\n",
      "512/512 [==============================] - 0s 213us/sample - loss: 0.0467 - acc: 0.9978 - val_loss: 0.0508 - val_acc: 0.9961\n",
      "Epoch 55/100\n",
      "512/512 [==============================] - 0s 205us/sample - loss: 0.0461 - acc: 0.9978 - val_loss: 0.0503 - val_acc: 0.9961\n",
      "Epoch 56/100\n",
      "512/512 [==============================] - 0s 215us/sample - loss: 0.0456 - acc: 0.9978 - val_loss: 0.0497 - val_acc: 0.9961\n",
      "Epoch 57/100\n",
      "512/512 [==============================] - 0s 228us/sample - loss: 0.0450 - acc: 0.9978 - val_loss: 0.0492 - val_acc: 0.9961\n",
      "Epoch 58/100\n",
      "512/512 [==============================] - 0s 197us/sample - loss: 0.0446 - acc: 0.9978 - val_loss: 0.0487 - val_acc: 0.9961\n",
      "Epoch 59/100\n",
      "512/512 [==============================] - 0s 185us/sample - loss: 0.0440 - acc: 0.9978 - val_loss: 0.0482 - val_acc: 0.9961\n",
      "Epoch 60/100\n",
      "512/512 [==============================] - 0s 174us/sample - loss: 0.0435 - acc: 0.9978 - val_loss: 0.0476 - val_acc: 0.9961\n",
      "Epoch 61/100\n",
      "512/512 [==============================] - 0s 187us/sample - loss: 0.0430 - acc: 0.9978 - val_loss: 0.0471 - val_acc: 0.9961\n",
      "Epoch 62/100\n",
      "512/512 [==============================] - 0s 209us/sample - loss: 0.0424 - acc: 0.9978 - val_loss: 0.0465 - val_acc: 0.9961\n",
      "Epoch 63/100\n",
      "512/512 [==============================] - 0s 178us/sample - loss: 0.0420 - acc: 0.9978 - val_loss: 0.0461 - val_acc: 0.9961\n",
      "Epoch 64/100\n",
      "512/512 [==============================] - 0s 176us/sample - loss: 0.0415 - acc: 0.9978 - val_loss: 0.0455 - val_acc: 0.9961\n",
      "Epoch 65/100\n",
      "512/512 [==============================] - 0s 193us/sample - loss: 0.0410 - acc: 0.9978 - val_loss: 0.0450 - val_acc: 0.9961\n",
      "Epoch 66/100\n",
      "512/512 [==============================] - 0s 203us/sample - loss: 0.0405 - acc: 0.9980 - val_loss: 0.0445 - val_acc: 0.9961\n",
      "Epoch 67/100\n",
      "512/512 [==============================] - 0s 189us/sample - loss: 0.0401 - acc: 0.9980 - val_loss: 0.0440 - val_acc: 0.9961\n",
      "Epoch 68/100\n",
      "512/512 [==============================] - 0s 180us/sample - loss: 0.0396 - acc: 0.9980 - val_loss: 0.0436 - val_acc: 0.9961\n",
      "Epoch 69/100\n",
      "512/512 [==============================] - 0s 213us/sample - loss: 0.0392 - acc: 0.9983 - val_loss: 0.0431 - val_acc: 0.9961\n",
      "Epoch 70/100\n",
      "512/512 [==============================] - 0s 213us/sample - loss: 0.0387 - acc: 0.9980 - val_loss: 0.0427 - val_acc: 0.9961\n",
      "Epoch 71/100\n",
      "512/512 [==============================] - 0s 203us/sample - loss: 0.0383 - acc: 0.9980 - val_loss: 0.0422 - val_acc: 0.9961\n",
      "Epoch 72/100\n",
      "512/512 [==============================] - 0s 197us/sample - loss: 0.0378 - acc: 0.9980 - val_loss: 0.0417 - val_acc: 0.9971\n",
      "Epoch 73/100\n",
      "512/512 [==============================] - 0s 180us/sample - loss: 0.0374 - acc: 0.9983 - val_loss: 0.0412 - val_acc: 0.9971\n",
      "Epoch 74/100\n",
      "512/512 [==============================] - 0s 207us/sample - loss: 0.0370 - acc: 0.9983 - val_loss: 0.0407 - val_acc: 0.9971\n",
      "Epoch 75/100\n",
      "512/512 [==============================] - 0s 203us/sample - loss: 0.0365 - acc: 0.9983 - val_loss: 0.0403 - val_acc: 0.9971\n",
      "Epoch 76/100\n",
      "512/512 [==============================] - 0s 182us/sample - loss: 0.0361 - acc: 0.9983 - val_loss: 0.0399 - val_acc: 0.9971\n",
      "Epoch 77/100\n",
      "512/512 [==============================] - 0s 197us/sample - loss: 0.0357 - acc: 0.9983 - val_loss: 0.0394 - val_acc: 0.9980\n",
      "Epoch 78/100\n",
      "512/512 [==============================] - 0s 189us/sample - loss: 0.0353 - acc: 0.9983 - val_loss: 0.0390 - val_acc: 0.9971\n",
      "Epoch 79/100\n",
      "512/512 [==============================] - 0s 211us/sample - loss: 0.0349 - acc: 0.9983 - val_loss: 0.0386 - val_acc: 0.9980\n",
      "Epoch 80/100\n",
      "512/512 [==============================] - 0s 207us/sample - loss: 0.0345 - acc: 0.9983 - val_loss: 0.0381 - val_acc: 0.9980\n",
      "Epoch 81/100\n",
      "512/512 [==============================] - 0s 185us/sample - loss: 0.0341 - acc: 0.9983 - val_loss: 0.0377 - val_acc: 0.9980\n",
      "Epoch 82/100\n",
      "512/512 [==============================] - 0s 183us/sample - loss: 0.0337 - acc: 0.9983 - val_loss: 0.0373 - val_acc: 0.9980\n",
      "Epoch 83/100\n",
      "512/512 [==============================] - 0s 201us/sample - loss: 0.0334 - acc: 0.9983 - val_loss: 0.0368 - val_acc: 0.9980\n",
      "Epoch 84/100\n",
      "512/512 [==============================] - 0s 191us/sample - loss: 0.0330 - acc: 0.9983 - val_loss: 0.0366 - val_acc: 0.9980\n",
      "Epoch 85/100\n",
      "512/512 [==============================] - 0s 187us/sample - loss: 0.0326 - acc: 0.9983 - val_loss: 0.0361 - val_acc: 0.9980\n",
      "Epoch 86/100\n",
      "512/512 [==============================] - 0s 199us/sample - loss: 0.0322 - acc: 0.9985 - val_loss: 0.0357 - val_acc: 0.9980\n",
      "Epoch 87/100\n",
      "512/512 [==============================] - 0s 209us/sample - loss: 0.0319 - acc: 0.9985 - val_loss: 0.0354 - val_acc: 0.9980\n",
      "Epoch 88/100\n",
      "512/512 [==============================] - 0s 205us/sample - loss: 0.0315 - acc: 0.9988 - val_loss: 0.0349 - val_acc: 0.9980\n",
      "Epoch 89/100\n",
      "512/512 [==============================] - 0s 209us/sample - loss: 0.0311 - acc: 0.9988 - val_loss: 0.0346 - val_acc: 0.9980\n",
      "Epoch 90/100\n",
      "512/512 [==============================] - 0s 189us/sample - loss: 0.0308 - acc: 0.9988 - val_loss: 0.0342 - val_acc: 0.9980\n",
      "Epoch 91/100\n",
      "512/512 [==============================] - 0s 189us/sample - loss: 0.0304 - acc: 0.9990 - val_loss: 0.0337 - val_acc: 0.9980\n",
      "Epoch 92/100\n",
      "512/512 [==============================] - 0s 203us/sample - loss: 0.0301 - acc: 0.9990 - val_loss: 0.0334 - val_acc: 0.9980\n",
      "Epoch 93/100\n",
      "512/512 [==============================] - 0s 178us/sample - loss: 0.0297 - acc: 0.9993 - val_loss: 0.0331 - val_acc: 0.9990\n",
      "Epoch 94/100\n",
      "512/512 [==============================] - 0s 191us/sample - loss: 0.0294 - acc: 0.9993 - val_loss: 0.0327 - val_acc: 0.9990\n",
      "Epoch 95/100\n",
      "512/512 [==============================] - 0s 195us/sample - loss: 0.0291 - acc: 0.9993 - val_loss: 0.0323 - val_acc: 0.9990\n",
      "Epoch 96/100\n",
      "512/512 [==============================] - 0s 203us/sample - loss: 0.0288 - acc: 0.9990 - val_loss: 0.0320 - val_acc: 0.9990\n",
      "Epoch 97/100\n",
      "512/512 [==============================] - 0s 189us/sample - loss: 0.0284 - acc: 0.9993 - val_loss: 0.0317 - val_acc: 0.9990\n",
      "Epoch 98/100\n",
      "512/512 [==============================] - 0s 193us/sample - loss: 0.0281 - acc: 0.9993 - val_loss: 0.0312 - val_acc: 1.0000\n",
      "Epoch 99/100\n",
      "512/512 [==============================] - 0s 207us/sample - loss: 0.0278 - acc: 0.9993 - val_loss: 0.0309 - val_acc: 1.0000\n",
      "Epoch 100/100\n",
      "512/512 [==============================] - 0s 203us/sample - loss: 0.0275 - acc: 0.9993 - val_loss: 0.0305 - val_acc: 1.0000\n"
     ]
    }
   ],
   "source": [
    "# Treinando os dados de Teste da Rede Neural: \n",
    "\n",
    "treino = redeNeural.fit(X_Treino, Y_Treino, validation_split=0.2, epochs=100, batch_size=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A Rede Neural foi treinada com 100 épocas, e teve acurácia de 97% para os dados de Treino."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Previsão com os dados de Teste: \n",
    "\n",
    "previsao = redeNeural.predict(X_Teste) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[20  0  0  0  0  0  0  0]\n",
      " [ 0 12  0  0  0  0  0  0]\n",
      " [ 0  0 26  0  0  0  0  0]\n",
      " [ 0  0  0 14  0  0  0  0]\n",
      " [ 0  0  0  0 28  0  0  0]\n",
      " [ 0  0  0  0  0 15  0  0]\n",
      " [ 0  0  0  0  0  0 20  0]\n",
      " [ 0  0  0  0  0  0  0 25]]\n"
     ]
    }
   ],
   "source": [
    "# Matriz de confusão para ver os acertos e erros: \n",
    "\n",
    "confusao = confusion_matrix(Y_Teste.argmax(axis=1), previsao.argmax(axis=1))\n",
    "print(confusao)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculando a Acurácia: \n",
    "\n",
    "accuracy_score(Y_Teste, previsao)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
