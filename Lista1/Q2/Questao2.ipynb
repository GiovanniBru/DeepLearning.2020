{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aluno: Giovanni Bruno Travassos de Carvalho - 11506849\n",
    "\n",
    "Resolução da segunda questão da primeira lista de exercícios de Deep Learning\n",
    "\n",
    "Professor: Tiago Maritan "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Questão 2 \n",
    "Implemente uma rede perceptron de múltiplas camadas e utilize-a para aproximar as duas\n",
    "funções abaixo. Em seguida, compare os resultados com as curvas exatas. No caso da letra\n",
    "(b), apresente também a curva do erro médio de treinamento com relação ao número de\n",
    "épocas e a curva do erro médio com o conjunto de validação.\n",
    "\n",
    "a) a função lógica XOR\n",
    "\n",
    "b) f(x) = sen(πx) / πx , 0 ≤ x ≤ 4  \n",
    "\n",
    "Dica: Selecione um conjunto de amostras para cada função (onde x é a entrada e f(x) é a saída\n",
    "desejada - rótulo). Essas amostras devem ser divididas em, pelo menos dois conjuntos:\n",
    "treinamento e validação. Treine um perceptron de múltiplas camada para que ele aprenda a\n",
    "aproximar a função a partir do conjunto de treinamento, e vá testando com o conjunto de\n",
    "validação.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Primeira Etapa: Geração dos dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "def generator():\n",
    "    \n",
    "    samples=1000\n",
    "    \n",
    "    random.seed(234)\n",
    "\n",
    "    X = []\n",
    "    Y = []\n",
    "\n",
    "    for i in range(samples):\n",
    "        \n",
    "        rand = random.uniform(0, 4)\n",
    "        if(rand == 0):\n",
    "            random.uniform(0, 4)\n",
    "        x = rand\n",
    "        y = (math.sin(math.pi * x)) / (math.pi * x)\n",
    "        \n",
    "        X.append(x)\n",
    "        Y.append(y)\n",
    "    \n",
    "    X = np.array(X)\n",
    "    Y = np.array(Y)\n",
    "    return  X, Y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Segunda Etapa: Rede Neural de Múltiplas Camadas "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Giovanni\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\Giovanni\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\Giovanni\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\Giovanni\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\Giovanni\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\Giovanni\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# Importação das Bibliotecas:\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, r2_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Letra A = Função lógica XOR "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Arrays de Entrada e Saída: \n",
    "\n",
    "entrada = [[0,0], [0,1], [1,0], [1,1]]\n",
    "saida = [[0], [1], [1], [0]]\n",
    "\n",
    "entrada = np.array(entrada)\n",
    "saida = np.array(saida)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 2)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "entrada.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 1)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "saida.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Divisão entre Treino e Teste: \n",
    "\n",
    "X_Treino = entrada\n",
    "Y_Treino = entrada\n",
    "X_Teste = saida \n",
    "Y_Teste = saida "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0]\n",
      " [0 1]\n",
      " [1 0]\n",
      " [1 1]]\n"
     ]
    }
   ],
   "source": [
    "print(X_Treino)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0]\n",
      " [1]\n",
      " [1]\n",
      " [0]]\n"
     ]
    }
   ],
   "source": [
    "print(X_Teste)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalização: \n",
    "\n",
    "ss = StandardScaler()\n",
    "X_Treino = ss.fit_transform(X_Treino)\n",
    "X_Teste = ss.fit_transform(X_Teste)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Giovanni\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "# Construindo a Rede Neural: \n",
    "\n",
    "rede = tf.keras.models.Sequential() # Inicialização \n",
    "\n",
    "# Criarei 1 camada de entrada, 2 camadas ocultas, e 1 camada de saída: \n",
    "rede.add(tf.keras.layers.Dense(units=8, activation='relu', input_dim=2)) # Entrada\n",
    "#rede.add(tf.keras.layers.Dense(units=2, activation='relu')) # Camada oculta com 4 unidades\n",
    "rede.add(tf.keras.layers.Dense(units=4, activation='relu')) # Camada oculta com 4 unidades\n",
    "#rede.add(Dropout(0.2))\n",
    "rede.add(tf.keras.layers.Dense(units=4, activation='relu')) # Camada oculta com 2 unidades\n",
    "rede.add(tf.keras.layers.Dense(units=2, activation='softmax')) # Camada de Saída "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Giovanni\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\utils\\losses_utils.py:170: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n"
     ]
    }
   ],
   "source": [
    "# Compilando a Rede Neural: \n",
    "rede.compile(loss = 'mean_squared_error', optimizer = 'adam' , metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 3 samples, validate on 1 samples\n",
      "WARNING:tensorflow:From C:\\Users\\Giovanni\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/100\n",
      "3/3 [==============================] - 0s 137ms/sample - loss: 0.1884 - acc: 1.0000 - val_loss: 0.2773 - val_acc: 0.0000e+00\n",
      "Epoch 2/100\n",
      "3/3 [==============================] - 0s 2ms/sample - loss: 0.1870 - acc: 1.0000 - val_loss: 0.2778 - val_acc: 0.0000e+00\n",
      "Epoch 3/100\n",
      "3/3 [==============================] - 0s 2ms/sample - loss: 0.1855 - acc: 1.0000 - val_loss: 0.2782 - val_acc: 0.0000e+00\n",
      "Epoch 4/100\n",
      "3/3 [==============================] - 0s 1ms/sample - loss: 0.1841 - acc: 1.0000 - val_loss: 0.2786 - val_acc: 0.0000e+00\n",
      "Epoch 5/100\n",
      "3/3 [==============================] - 0s 4ms/sample - loss: 0.1826 - acc: 1.0000 - val_loss: 0.2790 - val_acc: 0.0000e+00\n",
      "Epoch 6/100\n",
      "3/3 [==============================] - 0s 2ms/sample - loss: 0.1812 - acc: 1.0000 - val_loss: 0.2794 - val_acc: 0.0000e+00\n",
      "Epoch 7/100\n",
      "3/3 [==============================] - 0s 3ms/sample - loss: 0.1798 - acc: 1.0000 - val_loss: 0.2799 - val_acc: 0.0000e+00\n",
      "Epoch 8/100\n",
      "3/3 [==============================] - 0s 1ms/sample - loss: 0.1784 - acc: 1.0000 - val_loss: 0.2803 - val_acc: 0.0000e+00\n",
      "Epoch 9/100\n",
      "3/3 [==============================] - 0s 2ms/sample - loss: 0.1770 - acc: 1.0000 - val_loss: 0.2808 - val_acc: 0.0000e+00\n",
      "Epoch 10/100\n",
      "3/3 [==============================] - 0s 3ms/sample - loss: 0.1756 - acc: 1.0000 - val_loss: 0.2812 - val_acc: 0.0000e+00\n",
      "Epoch 11/100\n",
      "3/3 [==============================] - 0s 2ms/sample - loss: 0.1742 - acc: 1.0000 - val_loss: 0.2817 - val_acc: 0.0000e+00\n",
      "Epoch 12/100\n",
      "3/3 [==============================] - 0s 4ms/sample - loss: 0.1729 - acc: 1.0000 - val_loss: 0.2822 - val_acc: 0.0000e+00\n",
      "Epoch 13/100\n",
      "3/3 [==============================] - 0s 3ms/sample - loss: 0.1715 - acc: 1.0000 - val_loss: 0.2827 - val_acc: 0.0000e+00\n",
      "Epoch 14/100\n",
      "3/3 [==============================] - 0s 4ms/sample - loss: 0.1702 - acc: 1.0000 - val_loss: 0.2831 - val_acc: 0.0000e+00\n",
      "Epoch 15/100\n",
      "3/3 [==============================] - 0s 2ms/sample - loss: 0.1689 - acc: 1.0000 - val_loss: 0.2836 - val_acc: 0.0000e+00\n",
      "Epoch 16/100\n",
      "3/3 [==============================] - 0s 3ms/sample - loss: 0.1676 - acc: 1.0000 - val_loss: 0.2841 - val_acc: 0.0000e+00\n",
      "Epoch 17/100\n",
      "3/3 [==============================] - 0s 3ms/sample - loss: 0.1663 - acc: 1.0000 - val_loss: 0.2846 - val_acc: 0.0000e+00\n",
      "Epoch 18/100\n",
      "3/3 [==============================] - 0s 2ms/sample - loss: 0.1650 - acc: 1.0000 - val_loss: 0.2852 - val_acc: 0.0000e+00\n",
      "Epoch 19/100\n",
      "3/3 [==============================] - 0s 2ms/sample - loss: 0.1637 - acc: 1.0000 - val_loss: 0.2857 - val_acc: 0.0000e+00\n",
      "Epoch 20/100\n",
      "3/3 [==============================] - 0s 2ms/sample - loss: 0.1625 - acc: 1.0000 - val_loss: 0.2862 - val_acc: 0.0000e+00\n",
      "Epoch 21/100\n",
      "3/3 [==============================] - 0s 3ms/sample - loss: 0.1612 - acc: 1.0000 - val_loss: 0.2868 - val_acc: 0.0000e+00\n",
      "Epoch 22/100\n",
      "3/3 [==============================] - 0s 2ms/sample - loss: 0.1600 - acc: 1.0000 - val_loss: 0.2873 - val_acc: 0.0000e+00\n",
      "Epoch 23/100\n",
      "3/3 [==============================] - 0s 2ms/sample - loss: 0.1588 - acc: 1.0000 - val_loss: 0.2879 - val_acc: 0.0000e+00\n",
      "Epoch 24/100\n",
      "3/3 [==============================] - 0s 2ms/sample - loss: 0.1576 - acc: 1.0000 - val_loss: 0.2884 - val_acc: 0.0000e+00\n",
      "Epoch 25/100\n",
      "3/3 [==============================] - 0s 3ms/sample - loss: 0.1564 - acc: 1.0000 - val_loss: 0.2890 - val_acc: 0.0000e+00\n",
      "Epoch 26/100\n",
      "3/3 [==============================] - 0s 4ms/sample - loss: 0.1553 - acc: 1.0000 - val_loss: 0.2896 - val_acc: 0.0000e+00\n",
      "Epoch 27/100\n",
      "3/3 [==============================] - 0s 2ms/sample - loss: 0.1541 - acc: 1.0000 - val_loss: 0.2902 - val_acc: 0.0000e+00\n",
      "Epoch 28/100\n",
      "3/3 [==============================] - 0s 2ms/sample - loss: 0.1530 - acc: 1.0000 - val_loss: 0.2908 - val_acc: 0.0000e+00\n",
      "Epoch 29/100\n",
      "3/3 [==============================] - 0s 2ms/sample - loss: 0.1519 - acc: 1.0000 - val_loss: 0.2914 - val_acc: 0.0000e+00\n",
      "Epoch 30/100\n",
      "3/3 [==============================] - 0s 4ms/sample - loss: 0.1508 - acc: 1.0000 - val_loss: 0.2920 - val_acc: 0.0000e+00\n",
      "Epoch 31/100\n",
      "3/3 [==============================] - 0s 3ms/sample - loss: 0.1497 - acc: 1.0000 - val_loss: 0.2926 - val_acc: 0.0000e+00\n",
      "Epoch 32/100\n",
      "3/3 [==============================] - 0s 2ms/sample - loss: 0.1486 - acc: 1.0000 - val_loss: 0.2932 - val_acc: 0.0000e+00\n",
      "Epoch 33/100\n",
      "3/3 [==============================] - 0s 2ms/sample - loss: 0.1475 - acc: 1.0000 - val_loss: 0.2939 - val_acc: 0.0000e+00\n",
      "Epoch 34/100\n",
      "3/3 [==============================] - 0s 2ms/sample - loss: 0.1465 - acc: 1.0000 - val_loss: 0.2945 - val_acc: 0.0000e+00\n",
      "Epoch 35/100\n",
      "3/3 [==============================] - 0s 2ms/sample - loss: 0.1455 - acc: 1.0000 - val_loss: 0.2952 - val_acc: 0.0000e+00\n",
      "Epoch 36/100\n",
      "3/3 [==============================] - 0s 2ms/sample - loss: 0.1445 - acc: 1.0000 - val_loss: 0.2958 - val_acc: 0.0000e+00\n",
      "Epoch 37/100\n",
      "3/3 [==============================] - 0s 2ms/sample - loss: 0.1436 - acc: 1.0000 - val_loss: 0.2965 - val_acc: 0.0000e+00\n",
      "Epoch 38/100\n",
      "3/3 [==============================] - 0s 6ms/sample - loss: 0.1426 - acc: 1.0000 - val_loss: 0.2971 - val_acc: 0.0000e+00\n",
      "Epoch 39/100\n",
      "3/3 [==============================] - 0s 2ms/sample - loss: 0.1416 - acc: 1.0000 - val_loss: 0.2977 - val_acc: 0.0000e+00\n",
      "Epoch 40/100\n",
      "3/3 [==============================] - 0s 2ms/sample - loss: 0.1407 - acc: 1.0000 - val_loss: 0.2984 - val_acc: 0.0000e+00\n",
      "Epoch 41/100\n",
      "3/3 [==============================] - 0s 2ms/sample - loss: 0.1398 - acc: 1.0000 - val_loss: 0.2991 - val_acc: 0.0000e+00\n",
      "Epoch 42/100\n",
      "3/3 [==============================] - 0s 2ms/sample - loss: 0.1389 - acc: 1.0000 - val_loss: 0.2998 - val_acc: 0.0000e+00\n",
      "Epoch 43/100\n",
      "3/3 [==============================] - 0s 3ms/sample - loss: 0.1380 - acc: 1.0000 - val_loss: 0.3005 - val_acc: 0.0000e+00\n",
      "Epoch 44/100\n",
      "3/3 [==============================] - 0s 2ms/sample - loss: 0.1371 - acc: 1.0000 - val_loss: 0.3012 - val_acc: 0.0000e+00\n",
      "Epoch 45/100\n",
      "3/3 [==============================] - 0s 5ms/sample - loss: 0.1363 - acc: 1.0000 - val_loss: 0.3019 - val_acc: 0.0000e+00\n",
      "Epoch 46/100\n",
      "3/3 [==============================] - 0s 3ms/sample - loss: 0.1354 - acc: 1.0000 - val_loss: 0.3026 - val_acc: 0.0000e+00\n",
      "Epoch 47/100\n",
      "3/3 [==============================] - 0s 2ms/sample - loss: 0.1346 - acc: 1.0000 - val_loss: 0.3033 - val_acc: 0.0000e+00\n",
      "Epoch 48/100\n",
      "3/3 [==============================] - 0s 1ms/sample - loss: 0.1338 - acc: 1.0000 - val_loss: 0.3041 - val_acc: 0.0000e+00\n",
      "Epoch 49/100\n",
      "3/3 [==============================] - 0s 1ms/sample - loss: 0.1330 - acc: 1.0000 - val_loss: 0.3048 - val_acc: 0.0000e+00\n",
      "Epoch 50/100\n",
      "3/3 [==============================] - 0s 5ms/sample - loss: 0.1322 - acc: 1.0000 - val_loss: 0.3056 - val_acc: 0.0000e+00\n",
      "Epoch 51/100\n",
      "3/3 [==============================] - 0s 4ms/sample - loss: 0.1314 - acc: 1.0000 - val_loss: 0.3063 - val_acc: 0.0000e+00\n",
      "Epoch 52/100\n",
      "3/3 [==============================] - 0s 3ms/sample - loss: 0.1306 - acc: 1.0000 - val_loss: 0.3071 - val_acc: 0.0000e+00\n",
      "Epoch 53/100\n",
      "3/3 [==============================] - 0s 3ms/sample - loss: 0.1299 - acc: 1.0000 - val_loss: 0.3079 - val_acc: 0.0000e+00\n",
      "Epoch 54/100\n",
      "3/3 [==============================] - 0s 2ms/sample - loss: 0.1291 - acc: 1.0000 - val_loss: 0.3086 - val_acc: 0.0000e+00\n",
      "Epoch 55/100\n",
      "3/3 [==============================] - 0s 2ms/sample - loss: 0.1284 - acc: 1.0000 - val_loss: 0.3094 - val_acc: 0.0000e+00\n",
      "Epoch 56/100\n",
      "3/3 [==============================] - 0s 2ms/sample - loss: 0.1277 - acc: 1.0000 - val_loss: 0.3102 - val_acc: 0.0000e+00\n",
      "Epoch 57/100\n",
      "3/3 [==============================] - 0s 3ms/sample - loss: 0.1270 - acc: 1.0000 - val_loss: 0.3110 - val_acc: 0.0000e+00\n",
      "Epoch 58/100\n",
      "3/3 [==============================] - 0s 3ms/sample - loss: 0.1263 - acc: 1.0000 - val_loss: 0.3117 - val_acc: 0.0000e+00\n",
      "Epoch 59/100\n",
      "3/3 [==============================] - 0s 3ms/sample - loss: 0.1256 - acc: 1.0000 - val_loss: 0.3125 - val_acc: 0.0000e+00\n",
      "Epoch 60/100\n",
      "3/3 [==============================] - 0s 3ms/sample - loss: 0.1249 - acc: 1.0000 - val_loss: 0.3133 - val_acc: 0.0000e+00\n",
      "Epoch 61/100\n",
      "3/3 [==============================] - 0s 2ms/sample - loss: 0.1243 - acc: 1.0000 - val_loss: 0.3141 - val_acc: 0.0000e+00\n",
      "Epoch 62/100\n",
      "3/3 [==============================] - 0s 1ms/sample - loss: 0.1236 - acc: 1.0000 - val_loss: 0.3150 - val_acc: 0.0000e+00\n",
      "Epoch 63/100\n",
      "3/3 [==============================] - 0s 2ms/sample - loss: 0.1230 - acc: 1.0000 - val_loss: 0.3158 - val_acc: 0.0000e+00\n",
      "Epoch 64/100\n",
      "3/3 [==============================] - 0s 2ms/sample - loss: 0.1224 - acc: 1.0000 - val_loss: 0.3166 - val_acc: 0.0000e+00\n",
      "Epoch 65/100\n",
      "3/3 [==============================] - 0s 2ms/sample - loss: 0.1217 - acc: 1.0000 - val_loss: 0.3174 - val_acc: 0.0000e+00\n",
      "Epoch 66/100\n",
      "3/3 [==============================] - 0s 1ms/sample - loss: 0.1211 - acc: 1.0000 - val_loss: 0.3182 - val_acc: 0.0000e+00\n",
      "Epoch 67/100\n",
      "3/3 [==============================] - 0s 4ms/sample - loss: 0.1205 - acc: 1.0000 - val_loss: 0.3190 - val_acc: 0.0000e+00\n",
      "Epoch 68/100\n",
      "3/3 [==============================] - 0s 2ms/sample - loss: 0.1200 - acc: 1.0000 - val_loss: 0.3198 - val_acc: 0.0000e+00\n",
      "Epoch 69/100\n",
      "3/3 [==============================] - 0s 2ms/sample - loss: 0.1194 - acc: 1.0000 - val_loss: 0.3207 - val_acc: 0.0000e+00\n",
      "Epoch 70/100\n",
      "3/3 [==============================] - 0s 2ms/sample - loss: 0.1188 - acc: 1.0000 - val_loss: 0.3215 - val_acc: 0.0000e+00\n",
      "Epoch 71/100\n",
      "3/3 [==============================] - 0s 2ms/sample - loss: 0.1183 - acc: 1.0000 - val_loss: 0.3223 - val_acc: 0.0000e+00\n",
      "Epoch 72/100\n",
      "3/3 [==============================] - 0s 2ms/sample - loss: 0.1177 - acc: 1.0000 - val_loss: 0.3231 - val_acc: 0.0000e+00\n",
      "Epoch 73/100\n",
      "3/3 [==============================] - 0s 2ms/sample - loss: 0.1172 - acc: 1.0000 - val_loss: 0.3239 - val_acc: 0.0000e+00\n",
      "Epoch 74/100\n",
      "3/3 [==============================] - 0s 1ms/sample - loss: 0.1167 - acc: 1.0000 - val_loss: 0.3247 - val_acc: 0.0000e+00\n",
      "Epoch 75/100\n",
      "3/3 [==============================] - 0s 3ms/sample - loss: 0.1162 - acc: 1.0000 - val_loss: 0.3255 - val_acc: 0.0000e+00\n",
      "Epoch 76/100\n",
      "3/3 [==============================] - 0s 1ms/sample - loss: 0.1156 - acc: 1.0000 - val_loss: 0.3263 - val_acc: 0.0000e+00\n",
      "Epoch 77/100\n",
      "3/3 [==============================] - 0s 2ms/sample - loss: 0.1151 - acc: 1.0000 - val_loss: 0.3272 - val_acc: 0.0000e+00\n",
      "Epoch 78/100\n",
      "3/3 [==============================] - 0s 2ms/sample - loss: 0.1147 - acc: 1.0000 - val_loss: 0.3280 - val_acc: 0.0000e+00\n",
      "Epoch 79/100\n",
      "3/3 [==============================] - 0s 2ms/sample - loss: 0.1142 - acc: 1.0000 - val_loss: 0.3288 - val_acc: 0.0000e+00\n",
      "Epoch 80/100\n",
      "3/3 [==============================] - 0s 2ms/sample - loss: 0.1137 - acc: 1.0000 - val_loss: 0.3296 - val_acc: 0.0000e+00\n",
      "Epoch 81/100\n",
      "3/3 [==============================] - 0s 2ms/sample - loss: 0.1132 - acc: 1.0000 - val_loss: 0.3304 - val_acc: 0.0000e+00\n",
      "Epoch 82/100\n",
      "3/3 [==============================] - 0s 3ms/sample - loss: 0.1128 - acc: 1.0000 - val_loss: 0.3312 - val_acc: 0.0000e+00\n",
      "Epoch 83/100\n",
      "3/3 [==============================] - 0s 3ms/sample - loss: 0.1123 - acc: 1.0000 - val_loss: 0.3320 - val_acc: 0.0000e+00\n",
      "Epoch 84/100\n",
      "3/3 [==============================] - 0s 3ms/sample - loss: 0.1119 - acc: 1.0000 - val_loss: 0.3328 - val_acc: 0.0000e+00\n",
      "Epoch 85/100\n",
      "3/3 [==============================] - 0s 3ms/sample - loss: 0.1114 - acc: 1.0000 - val_loss: 0.3336 - val_acc: 0.0000e+00\n",
      "Epoch 86/100\n",
      "3/3 [==============================] - 0s 1ms/sample - loss: 0.1110 - acc: 1.0000 - val_loss: 0.3344 - val_acc: 0.0000e+00\n",
      "Epoch 87/100\n",
      "3/3 [==============================] - 0s 3ms/sample - loss: 0.1106 - acc: 1.0000 - val_loss: 0.3351 - val_acc: 0.0000e+00\n",
      "Epoch 88/100\n",
      "3/3 [==============================] - 0s 3ms/sample - loss: 0.1102 - acc: 1.0000 - val_loss: 0.3359 - val_acc: 0.0000e+00\n",
      "Epoch 89/100\n",
      "3/3 [==============================] - 0s 4ms/sample - loss: 0.1097 - acc: 1.0000 - val_loss: 0.3367 - val_acc: 0.0000e+00\n",
      "Epoch 90/100\n",
      "3/3 [==============================] - 0s 5ms/sample - loss: 0.1093 - acc: 1.0000 - val_loss: 0.3375 - val_acc: 0.0000e+00\n",
      "Epoch 91/100\n",
      "3/3 [==============================] - 0s 4ms/sample - loss: 0.1089 - acc: 1.0000 - val_loss: 0.3382 - val_acc: 0.0000e+00\n",
      "Epoch 92/100\n",
      "3/3 [==============================] - 0s 3ms/sample - loss: 0.1085 - acc: 1.0000 - val_loss: 0.3390 - val_acc: 0.0000e+00\n",
      "Epoch 93/100\n",
      "3/3 [==============================] - 0s 3ms/sample - loss: 0.1082 - acc: 1.0000 - val_loss: 0.3397 - val_acc: 0.0000e+00\n",
      "Epoch 94/100\n",
      "3/3 [==============================] - 0s 3ms/sample - loss: 0.1078 - acc: 1.0000 - val_loss: 0.3405 - val_acc: 0.0000e+00\n",
      "Epoch 95/100\n",
      "3/3 [==============================] - 0s 2ms/sample - loss: 0.1074 - acc: 1.0000 - val_loss: 0.3412 - val_acc: 0.0000e+00\n",
      "Epoch 96/100\n",
      "3/3 [==============================] - 0s 2ms/sample - loss: 0.1070 - acc: 1.0000 - val_loss: 0.3420 - val_acc: 0.0000e+00\n",
      "Epoch 97/100\n",
      "3/3 [==============================] - 0s 2ms/sample - loss: 0.1067 - acc: 1.0000 - val_loss: 0.3427 - val_acc: 0.0000e+00\n",
      "Epoch 98/100\n",
      "3/3 [==============================] - 0s 2ms/sample - loss: 0.1063 - acc: 1.0000 - val_loss: 0.3435 - val_acc: 0.0000e+00\n",
      "Epoch 99/100\n",
      "3/3 [==============================] - 0s 4ms/sample - loss: 0.1059 - acc: 1.0000 - val_loss: 0.3442 - val_acc: 0.0000e+00\n",
      "Epoch 100/100\n",
      "3/3 [==============================] - 0s 3ms/sample - loss: 0.1056 - acc: 1.0000 - val_loss: 0.3449 - val_acc: 0.0000e+00\n"
     ]
    }
   ],
   "source": [
    "# Treinando a rede neural: \n",
    "treino = rede.fit(X_Treino, Y_Treino, batch_size = 10, validation_split=0.2, epochs = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Error when checking input: expected dense_input to have shape (2,) but got array with shape (1,)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-14-1449a26650bd>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mprevisto\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrede\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_Teste\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, x, batch_size, verbose, steps, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1094\u001b[0m       \u001b[1;31m# batch size.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1095\u001b[0m       x, _, _ = self._standardize_user_data(\n\u001b[1;32m-> 1096\u001b[1;33m           x, check_steps=True, steps_name='steps', steps=steps)\n\u001b[0m\u001b[0;32m   1097\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1098\u001b[0m     if (self.run_eagerly or (isinstance(x, iterator_ops.EagerIterator) and\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[1;34m(self, x, y, sample_weight, class_weight, batch_size, check_steps, steps_name, steps, validation_split, shuffle)\u001b[0m\n\u001b[0;32m   2380\u001b[0m         \u001b[0mfeed_input_shapes\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2381\u001b[0m         \u001b[0mcheck_batch_axis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m  \u001b[1;31m# Don't enforce the batch size.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2382\u001b[1;33m         exception_prefix='input')\n\u001b[0m\u001b[0;32m   2383\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2384\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training_utils.py\u001b[0m in \u001b[0;36mstandardize_input_data\u001b[1;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[0;32m    360\u001b[0m                 \u001b[1;34m'Error when checking '\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mexception_prefix\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m': expected '\u001b[0m \u001b[1;33m+\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    361\u001b[0m                 \u001b[0mnames\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m' to have shape '\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 362\u001b[1;33m                 ' but got array with shape ' + str(data_shape))\n\u001b[0m\u001b[0;32m    363\u001b[0m   \u001b[1;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    364\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Error when checking input: expected dense_input to have shape (2,) but got array with shape (1,)"
     ]
    }
   ],
   "source": [
    "previsto = rede.predict(X_Teste)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Letra B = sen(πx) / πx , 0 ≤ x ≤ 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dados de entrada: \n",
    "\n",
    "Xb, Yb = generator(2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xb_Treino, Xb_Teste, Yb_Treino, Yb_Teste = train_test_split(Xb, Yb, test_size=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rede Neural: \n",
    "netw = Sequential()\n",
    "\n",
    "netw.add(Dense(10, activation='relu', input_shape=(1,)))\n",
    "#netw.add(Dropout(0.2))\n",
    "netw.add(Dense(8, activation='relu'))\n",
    "netw.add(Dense(4, activation='relu'))\n",
    "netw.add(Dense(1, activation='linear'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compilando:\n",
    "netw.compile(optimizer='adam', loss='mean_squared_error', metrics=['mean_squared_error'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1125 samples, validate on 375 samples\n",
      "Epoch 1/100\n",
      "1125/1125 [==============================] - 0s 318us/step - loss: 3.1281 - mean_squared_error: 3.1281 - val_loss: 2.7474 - val_mean_squared_error: 2.7474\n",
      "Epoch 2/100\n",
      "1125/1125 [==============================] - 0s 37us/step - loss: 2.1878 - mean_squared_error: 2.1878 - val_loss: 1.9296 - val_mean_squared_error: 1.9296\n",
      "Epoch 3/100\n",
      "1125/1125 [==============================] - 0s 36us/step - loss: 1.5230 - mean_squared_error: 1.5230 - val_loss: 1.3530 - val_mean_squared_error: 1.3530\n",
      "Epoch 4/100\n",
      "1125/1125 [==============================] - 0s 43us/step - loss: 1.0616 - mean_squared_error: 1.0616 - val_loss: 0.9386 - val_mean_squared_error: 0.9386\n",
      "Epoch 5/100\n",
      "1125/1125 [==============================] - 0s 62us/step - loss: 0.7280 - mean_squared_error: 0.7280 - val_loss: 0.6254 - val_mean_squared_error: 0.6254\n",
      "Epoch 6/100\n",
      "1125/1125 [==============================] - 0s 56us/step - loss: 0.3728 - mean_squared_error: 0.3728 - val_loss: 0.2030 - val_mean_squared_error: 0.2030\n",
      "Epoch 7/100\n",
      "1125/1125 [==============================] - 0s 36us/step - loss: 0.1208 - mean_squared_error: 0.1208 - val_loss: 0.0746 - val_mean_squared_error: 0.0746\n",
      "Epoch 8/100\n",
      "1125/1125 [==============================] - 0s 36us/step - loss: 0.0710 - mean_squared_error: 0.0710 - val_loss: 0.0609 - val_mean_squared_error: 0.0609\n",
      "Epoch 9/100\n",
      "1125/1125 [==============================] - 0s 42us/step - loss: 0.0683 - mean_squared_error: 0.0683 - val_loss: 0.0591 - val_mean_squared_error: 0.0591\n",
      "Epoch 10/100\n",
      "1125/1125 [==============================] - 0s 36us/step - loss: 0.0661 - mean_squared_error: 0.0661 - val_loss: 0.0578 - val_mean_squared_error: 0.0578\n",
      "Epoch 11/100\n",
      "1125/1125 [==============================] - 0s 38us/step - loss: 0.0640 - mean_squared_error: 0.0640 - val_loss: 0.0560 - val_mean_squared_error: 0.0560\n",
      "Epoch 12/100\n",
      "1125/1125 [==============================] - 0s 40us/step - loss: 0.0620 - mean_squared_error: 0.0620 - val_loss: 0.0544 - val_mean_squared_error: 0.0544\n",
      "Epoch 13/100\n",
      "1125/1125 [==============================] - 0s 37us/step - loss: 0.0601 - mean_squared_error: 0.0601 - val_loss: 0.0523 - val_mean_squared_error: 0.0523\n",
      "Epoch 14/100\n",
      "1125/1125 [==============================] - 0s 39us/step - loss: 0.0580 - mean_squared_error: 0.0580 - val_loss: 0.0504 - val_mean_squared_error: 0.0504\n",
      "Epoch 15/100\n",
      "1125/1125 [==============================] - 0s 46us/step - loss: 0.0560 - mean_squared_error: 0.0560 - val_loss: 0.0485 - val_mean_squared_error: 0.0485\n",
      "Epoch 16/100\n",
      "1125/1125 [==============================] - 0s 53us/step - loss: 0.0540 - mean_squared_error: 0.0540 - val_loss: 0.0466 - val_mean_squared_error: 0.0466\n",
      "Epoch 17/100\n",
      "1125/1125 [==============================] - 0s 54us/step - loss: 0.0520 - mean_squared_error: 0.0520 - val_loss: 0.0448 - val_mean_squared_error: 0.0448\n",
      "Epoch 18/100\n",
      "1125/1125 [==============================] - 0s 53us/step - loss: 0.0500 - mean_squared_error: 0.0500 - val_loss: 0.0428 - val_mean_squared_error: 0.0428\n",
      "Epoch 19/100\n",
      "1125/1125 [==============================] - 0s 45us/step - loss: 0.0480 - mean_squared_error: 0.0480 - val_loss: 0.0411 - val_mean_squared_error: 0.0411\n",
      "Epoch 20/100\n",
      "1125/1125 [==============================] - 0s 52us/step - loss: 0.0461 - mean_squared_error: 0.0461 - val_loss: 0.0392 - val_mean_squared_error: 0.0392\n",
      "Epoch 21/100\n",
      "1125/1125 [==============================] - 0s 46us/step - loss: 0.0442 - mean_squared_error: 0.0442 - val_loss: 0.0376 - val_mean_squared_error: 0.0376\n",
      "Epoch 22/100\n",
      "1125/1125 [==============================] - 0s 44us/step - loss: 0.0424 - mean_squared_error: 0.0424 - val_loss: 0.0359 - val_mean_squared_error: 0.0359\n",
      "Epoch 23/100\n",
      "1125/1125 [==============================] - 0s 86us/step - loss: 0.0406 - mean_squared_error: 0.0406 - val_loss: 0.0342 - val_mean_squared_error: 0.0342\n",
      "Epoch 24/100\n",
      "1125/1125 [==============================] - 0s 53us/step - loss: 0.0388 - mean_squared_error: 0.0388 - val_loss: 0.0327 - val_mean_squared_error: 0.0327\n",
      "Epoch 25/100\n",
      "1125/1125 [==============================] - 0s 63us/step - loss: 0.0371 - mean_squared_error: 0.0371 - val_loss: 0.0311 - val_mean_squared_error: 0.0311\n",
      "Epoch 26/100\n",
      "1125/1125 [==============================] - 0s 49us/step - loss: 0.0354 - mean_squared_error: 0.0354 - val_loss: 0.0295 - val_mean_squared_error: 0.0295\n",
      "Epoch 27/100\n",
      "1125/1125 [==============================] - 0s 68us/step - loss: 0.0338 - mean_squared_error: 0.0338 - val_loss: 0.0282 - val_mean_squared_error: 0.0282\n",
      "Epoch 28/100\n",
      "1125/1125 [==============================] - 0s 56us/step - loss: 0.0323 - mean_squared_error: 0.0323 - val_loss: 0.0268 - val_mean_squared_error: 0.0268\n",
      "Epoch 29/100\n",
      "1125/1125 [==============================] - 0s 55us/step - loss: 0.0308 - mean_squared_error: 0.0308 - val_loss: 0.0255 - val_mean_squared_error: 0.0255\n",
      "Epoch 30/100\n",
      "1125/1125 [==============================] - 0s 71us/step - loss: 0.0294 - mean_squared_error: 0.0294 - val_loss: 0.0242 - val_mean_squared_error: 0.0242\n",
      "Epoch 31/100\n",
      "1125/1125 [==============================] - 0s 54us/step - loss: 0.0280 - mean_squared_error: 0.0280 - val_loss: 0.0230 - val_mean_squared_error: 0.0230\n",
      "Epoch 32/100\n",
      "1125/1125 [==============================] - 0s 55us/step - loss: 0.0267 - mean_squared_error: 0.0267 - val_loss: 0.0219 - val_mean_squared_error: 0.0219\n",
      "Epoch 33/100\n",
      "1125/1125 [==============================] - 0s 49us/step - loss: 0.0255 - mean_squared_error: 0.0255 - val_loss: 0.0209 - val_mean_squared_error: 0.0209\n",
      "Epoch 34/100\n",
      "1125/1125 [==============================] - 0s 53us/step - loss: 0.0243 - mean_squared_error: 0.0243 - val_loss: 0.0198 - val_mean_squared_error: 0.0198\n",
      "Epoch 35/100\n",
      "1125/1125 [==============================] - 0s 47us/step - loss: 0.0232 - mean_squared_error: 0.0232 - val_loss: 0.0189 - val_mean_squared_error: 0.0189\n",
      "Epoch 36/100\n",
      "1125/1125 [==============================] - 0s 51us/step - loss: 0.0221 - mean_squared_error: 0.0221 - val_loss: 0.0180 - val_mean_squared_error: 0.0180\n",
      "Epoch 37/100\n",
      "1125/1125 [==============================] - 0s 52us/step - loss: 0.0211 - mean_squared_error: 0.0211 - val_loss: 0.0171 - val_mean_squared_error: 0.0171\n",
      "Epoch 38/100\n",
      "1125/1125 [==============================] - 0s 55us/step - loss: 0.0202 - mean_squared_error: 0.0202 - val_loss: 0.0164 - val_mean_squared_error: 0.0164\n",
      "Epoch 39/100\n",
      "1125/1125 [==============================] - 0s 55us/step - loss: 0.0193 - mean_squared_error: 0.0193 - val_loss: 0.0156 - val_mean_squared_error: 0.0156\n",
      "Epoch 40/100\n",
      "1125/1125 [==============================] - 0s 57us/step - loss: 0.0184 - mean_squared_error: 0.0184 - val_loss: 0.0149 - val_mean_squared_error: 0.0149\n",
      "Epoch 41/100\n",
      "1125/1125 [==============================] - 0s 59us/step - loss: 0.0176 - mean_squared_error: 0.0176 - val_loss: 0.0142 - val_mean_squared_error: 0.0142\n",
      "Epoch 42/100\n",
      "1125/1125 [==============================] - 0s 52us/step - loss: 0.0169 - mean_squared_error: 0.0169 - val_loss: 0.0136 - val_mean_squared_error: 0.0136\n",
      "Epoch 43/100\n",
      "1125/1125 [==============================] - 0s 56us/step - loss: 0.0162 - mean_squared_error: 0.0162 - val_loss: 0.0130 - val_mean_squared_error: 0.0130\n",
      "Epoch 44/100\n",
      "1125/1125 [==============================] - 0s 50us/step - loss: 0.0155 - mean_squared_error: 0.0155 - val_loss: 0.0126 - val_mean_squared_error: 0.0126\n",
      "Epoch 45/100\n",
      "1125/1125 [==============================] - 0s 50us/step - loss: 0.0149 - mean_squared_error: 0.0149 - val_loss: 0.0120 - val_mean_squared_error: 0.0120\n",
      "Epoch 46/100\n",
      "1125/1125 [==============================] - 0s 45us/step - loss: 0.0143 - mean_squared_error: 0.0143 - val_loss: 0.0116 - val_mean_squared_error: 0.0116\n",
      "Epoch 47/100\n",
      "1125/1125 [==============================] - 0s 52us/step - loss: 0.0137 - mean_squared_error: 0.0137 - val_loss: 0.0111 - val_mean_squared_error: 0.0111\n",
      "Epoch 48/100\n",
      "1125/1125 [==============================] - 0s 47us/step - loss: 0.0132 - mean_squared_error: 0.0132 - val_loss: 0.0107 - val_mean_squared_error: 0.0107\n",
      "Epoch 49/100\n",
      "1125/1125 [==============================] - 0s 47us/step - loss: 0.0127 - mean_squared_error: 0.0127 - val_loss: 0.0104 - val_mean_squared_error: 0.0104\n",
      "Epoch 50/100\n",
      "1125/1125 [==============================] - 0s 48us/step - loss: 0.0122 - mean_squared_error: 0.0122 - val_loss: 0.0099 - val_mean_squared_error: 0.0099\n",
      "Epoch 51/100\n",
      "1125/1125 [==============================] - 0s 43us/step - loss: 0.0118 - mean_squared_error: 0.0118 - val_loss: 0.0096 - val_mean_squared_error: 0.0096\n",
      "Epoch 52/100\n",
      "1125/1125 [==============================] - 0s 52us/step - loss: 0.0113 - mean_squared_error: 0.0113 - val_loss: 0.0093 - val_mean_squared_error: 0.0093\n",
      "Epoch 53/100\n",
      "1125/1125 [==============================] - 0s 51us/step - loss: 0.0110 - mean_squared_error: 0.0110 - val_loss: 0.0090 - val_mean_squared_error: 0.0090\n",
      "Epoch 54/100\n",
      "1125/1125 [==============================] - 0s 45us/step - loss: 0.0106 - mean_squared_error: 0.0106 - val_loss: 0.0088 - val_mean_squared_error: 0.0088\n",
      "Epoch 55/100\n",
      "1125/1125 [==============================] - 0s 41us/step - loss: 0.0103 - mean_squared_error: 0.0103 - val_loss: 0.0086 - val_mean_squared_error: 0.0086\n",
      "Epoch 56/100\n",
      "1125/1125 [==============================] - 0s 45us/step - loss: 0.0100 - mean_squared_error: 0.0100 - val_loss: 0.0084 - val_mean_squared_error: 0.0084\n",
      "Epoch 57/100\n",
      "1125/1125 [==============================] - 0s 57us/step - loss: 0.0098 - mean_squared_error: 0.0098 - val_loss: 0.0083 - val_mean_squared_error: 0.0083\n",
      "Epoch 58/100\n",
      "1125/1125 [==============================] - 0s 47us/step - loss: 0.0096 - mean_squared_error: 0.0096 - val_loss: 0.0081 - val_mean_squared_error: 0.0081\n",
      "Epoch 59/100\n",
      "1125/1125 [==============================] - 0s 58us/step - loss: 0.0094 - mean_squared_error: 0.0094 - val_loss: 0.0080 - val_mean_squared_error: 0.0080\n",
      "Epoch 60/100\n",
      "1125/1125 [==============================] - 0s 60us/step - loss: 0.0092 - mean_squared_error: 0.0092 - val_loss: 0.0079 - val_mean_squared_error: 0.0079\n",
      "Epoch 61/100\n",
      "1125/1125 [==============================] - 0s 52us/step - loss: 0.0090 - mean_squared_error: 0.0090 - val_loss: 0.0078 - val_mean_squared_error: 0.0078\n",
      "Epoch 62/100\n",
      "1125/1125 [==============================] - 0s 60us/step - loss: 0.0088 - mean_squared_error: 0.0088 - val_loss: 0.0077 - val_mean_squared_error: 0.0077\n",
      "Epoch 63/100\n",
      "1125/1125 [==============================] - 0s 47us/step - loss: 0.0087 - mean_squared_error: 0.0087 - val_loss: 0.0077 - val_mean_squared_error: 0.0077\n",
      "Epoch 64/100\n",
      "1125/1125 [==============================] - 0s 54us/step - loss: 0.0086 - mean_squared_error: 0.0086 - val_loss: 0.0076 - val_mean_squared_error: 0.0076\n",
      "Epoch 65/100\n",
      "1125/1125 [==============================] - 0s 48us/step - loss: 0.0085 - mean_squared_error: 0.0085 - val_loss: 0.0075 - val_mean_squared_error: 0.0075\n",
      "Epoch 66/100\n",
      "1125/1125 [==============================] - 0s 53us/step - loss: 0.0083 - mean_squared_error: 0.0083 - val_loss: 0.0075 - val_mean_squared_error: 0.0075\n",
      "Epoch 67/100\n",
      "1125/1125 [==============================] - 0s 69us/step - loss: 0.0082 - mean_squared_error: 0.0082 - val_loss: 0.0075 - val_mean_squared_error: 0.0075\n",
      "Epoch 68/100\n",
      "1125/1125 [==============================] - 0s 52us/step - loss: 0.0081 - mean_squared_error: 0.0081 - val_loss: 0.0074 - val_mean_squared_error: 0.0074\n",
      "Epoch 69/100\n",
      "1125/1125 [==============================] - 0s 52us/step - loss: 0.0081 - mean_squared_error: 0.0081 - val_loss: 0.0074 - val_mean_squared_error: 0.0074\n",
      "Epoch 70/100\n",
      "1125/1125 [==============================] - 0s 61us/step - loss: 0.0080 - mean_squared_error: 0.0080 - val_loss: 0.0073 - val_mean_squared_error: 0.0073\n",
      "Epoch 71/100\n",
      "1125/1125 [==============================] - 0s 56us/step - loss: 0.0079 - mean_squared_error: 0.0079 - val_loss: 0.0073 - val_mean_squared_error: 0.0073\n",
      "Epoch 72/100\n",
      "1125/1125 [==============================] - 0s 52us/step - loss: 0.0079 - mean_squared_error: 0.0079 - val_loss: 0.0073 - val_mean_squared_error: 0.0073\n",
      "Epoch 73/100\n",
      "1125/1125 [==============================] - 0s 48us/step - loss: 0.0078 - mean_squared_error: 0.0078 - val_loss: 0.0073 - val_mean_squared_error: 0.0073\n",
      "Epoch 74/100\n",
      "1125/1125 [==============================] - 0s 101us/step - loss: 0.0078 - mean_squared_error: 0.0078 - val_loss: 0.0073 - val_mean_squared_error: 0.0073\n",
      "Epoch 75/100\n",
      "1125/1125 [==============================] - 0s 57us/step - loss: 0.0077 - mean_squared_error: 0.0077 - val_loss: 0.0072 - val_mean_squared_error: 0.0072\n",
      "Epoch 76/100\n",
      "1125/1125 [==============================] - 0s 50us/step - loss: 0.0077 - mean_squared_error: 0.0077 - val_loss: 0.0072 - val_mean_squared_error: 0.0072\n",
      "Epoch 77/100\n",
      "1125/1125 [==============================] - 0s 49us/step - loss: 0.0076 - mean_squared_error: 0.0076 - val_loss: 0.0072 - val_mean_squared_error: 0.0072\n",
      "Epoch 78/100\n",
      "1125/1125 [==============================] - 0s 72us/step - loss: 0.0076 - mean_squared_error: 0.0076 - val_loss: 0.0072 - val_mean_squared_error: 0.0072\n",
      "Epoch 79/100\n",
      "1125/1125 [==============================] - 0s 55us/step - loss: 0.0076 - mean_squared_error: 0.0076 - val_loss: 0.0072 - val_mean_squared_error: 0.0072\n",
      "Epoch 80/100\n",
      "1125/1125 [==============================] - 0s 54us/step - loss: 0.0075 - mean_squared_error: 0.0075 - val_loss: 0.0072 - val_mean_squared_error: 0.0072\n",
      "Epoch 81/100\n",
      "1125/1125 [==============================] - 0s 57us/step - loss: 0.0075 - mean_squared_error: 0.0075 - val_loss: 0.0072 - val_mean_squared_error: 0.0072\n",
      "Epoch 82/100\n",
      "1125/1125 [==============================] - 0s 78us/step - loss: 0.0075 - mean_squared_error: 0.0075 - val_loss: 0.0072 - val_mean_squared_error: 0.0072\n",
      "Epoch 83/100\n",
      "1125/1125 [==============================] - 0s 56us/step - loss: 0.0075 - mean_squared_error: 0.0075 - val_loss: 0.0072 - val_mean_squared_error: 0.0072\n",
      "Epoch 84/100\n",
      "1125/1125 [==============================] - 0s 40us/step - loss: 0.0075 - mean_squared_error: 0.0075 - val_loss: 0.0072 - val_mean_squared_error: 0.0072\n",
      "Epoch 85/100\n",
      "1125/1125 [==============================] - 0s 41us/step - loss: 0.0075 - mean_squared_error: 0.0075 - val_loss: 0.0072 - val_mean_squared_error: 0.0072\n",
      "Epoch 86/100\n",
      "1125/1125 [==============================] - 0s 39us/step - loss: 0.0075 - mean_squared_error: 0.0075 - val_loss: 0.0072 - val_mean_squared_error: 0.0072\n",
      "Epoch 87/100\n",
      "1125/1125 [==============================] - 0s 38us/step - loss: 0.0074 - mean_squared_error: 0.0074 - val_loss: 0.0072 - val_mean_squared_error: 0.0072\n",
      "Epoch 88/100\n",
      "1125/1125 [==============================] - 0s 43us/step - loss: 0.0074 - mean_squared_error: 0.0074 - val_loss: 0.0072 - val_mean_squared_error: 0.0072\n",
      "Epoch 89/100\n",
      "1125/1125 [==============================] - 0s 43us/step - loss: 0.0074 - mean_squared_error: 0.0074 - val_loss: 0.0072 - val_mean_squared_error: 0.0072\n",
      "Epoch 90/100\n",
      "1125/1125 [==============================] - 0s 44us/step - loss: 0.0074 - mean_squared_error: 0.0074 - val_loss: 0.0072 - val_mean_squared_error: 0.0072\n",
      "Epoch 91/100\n",
      "1125/1125 [==============================] - 0s 40us/step - loss: 0.0074 - mean_squared_error: 0.0074 - val_loss: 0.0072 - val_mean_squared_error: 0.0072\n",
      "Epoch 92/100\n",
      "1125/1125 [==============================] - 0s 37us/step - loss: 0.0074 - mean_squared_error: 0.0074 - val_loss: 0.0072 - val_mean_squared_error: 0.0072\n",
      "Epoch 93/100\n",
      "1125/1125 [==============================] - 0s 42us/step - loss: 0.0074 - mean_squared_error: 0.0074 - val_loss: 0.0072 - val_mean_squared_error: 0.0072\n",
      "Epoch 94/100\n",
      "1125/1125 [==============================] - 0s 37us/step - loss: 0.0074 - mean_squared_error: 0.0074 - val_loss: 0.0072 - val_mean_squared_error: 0.0072\n",
      "Epoch 95/100\n",
      "1125/1125 [==============================] - 0s 36us/step - loss: 0.0074 - mean_squared_error: 0.0074 - val_loss: 0.0072 - val_mean_squared_error: 0.0072\n",
      "Epoch 96/100\n",
      "1125/1125 [==============================] - 0s 42us/step - loss: 0.0074 - mean_squared_error: 0.0074 - val_loss: 0.0072 - val_mean_squared_error: 0.0072\n",
      "Epoch 97/100\n",
      "1125/1125 [==============================] - 0s 39us/step - loss: 0.0074 - mean_squared_error: 0.0074 - val_loss: 0.0072 - val_mean_squared_error: 0.0072\n",
      "Epoch 98/100\n",
      "1125/1125 [==============================] - 0s 39us/step - loss: 0.0073 - mean_squared_error: 0.0073 - val_loss: 0.0072 - val_mean_squared_error: 0.0072\n",
      "Epoch 99/100\n",
      "1125/1125 [==============================] - 0s 42us/step - loss: 0.0074 - mean_squared_error: 0.0074 - val_loss: 0.0072 - val_mean_squared_error: 0.0072\n",
      "Epoch 100/100\n",
      "1125/1125 [==============================] - 0s 83us/step - loss: 0.0073 - mean_squared_error: 0.0073 - val_loss: 0.0072 - val_mean_squared_error: 0.0072\n"
     ]
    }
   ],
   "source": [
    "# Treinando: \n",
    "treinado = netw.fit(Xb_Treino, Yb_Treino, epochs=100, batch_size=64, validation_split=0.25, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_9\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_23 (Dense)             (None, 10)                20        \n",
      "_________________________________________________________________\n",
      "dense_24 (Dense)             (None, 5)                 55        \n",
      "_________________________________________________________________\n",
      "dense_25 (Dense)             (None, 1)                 6         \n",
      "=================================================================\n",
      "Total params: 81\n",
      "Trainable params: 81\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "netw.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No caso da letra\n",
    "(b), apresente também a curva do erro médio de treinamento com relação ao número de\n",
    "épocas e a curva do erro médio com o conjunto de validação.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score: 93.97%\n"
     ]
    }
   ],
   "source": [
    "# Previsão: \n",
    "\n",
    "previsao = netw.predict(Xb_Teste)\n",
    "print(f'Score: {round(r2_score(Yb_Teste, previsao)*100,2)}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
